{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_001_Shirota.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1QV90zNwZzPhx9J8dpIB249tHg3f330D-",
      "authorship_tag": "ABX9TyNtgbggsSi1DmsFz5tEisJL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srttkyk/desk/blob/master/BERT_001_Shirota.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnqyuxnCQZRG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "472d1f73-00a8-46be-84da-d65574900242"
      },
      "source": [
        "import random\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import torch \n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "#import torchtext\n",
        "from torchtext.legacy import data\n",
        "!pip install attrdict\n",
        "# 乱数のシードを設定\n",
        "torch.manual_seed(1234)\n",
        "np.random.seed(1234)\n",
        "random.seed(1234)\n",
        "%cd /content/drive/MyDrive/Colab Notebooks/ Global_AI_Challenge_2021\n",
        "%ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting attrdict\n",
            "  Downloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from attrdict) (1.15.0)\n",
            "Installing collected packages: attrdict\n",
            "Successfully installed attrdict-2.0.1\n",
            "/content/drive/MyDrive/Colab Notebooks/ Global_AI_Challenge_2021\n",
            "BERT_001_Shirota.ipynb  submission_002.tsv  submission.tsv\n",
            "BERT_ver1.ipynb         submission_003.tsv  \u001b[0m\u001b[01;34mutils\u001b[0m/\n",
            "\u001b[01;34mdata\u001b[0m/                   submission_004.tsv  utils-20211020T124115Z-001.zip\n",
            "GAIC_training.tsv       submission_005.tsv  \u001b[01;34mvocab\u001b[0m/\n",
            "submission_001.tsv      submission.csv      \u001b[01;34mweights\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-N_OygX-uyqo"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/ Global_AI_Challenge_2021/utils/')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCrbq-DatJmG"
      },
      "source": [
        "# 前処理と単語分割をまとめた関数を作成\n",
        "import re\n",
        "import string\n",
        "from utils.bert import BertTokenizer\n",
        "# フォルダ「utils」のbert.pyより\n",
        "\n",
        "def preprocessing_text(text):\n",
        "    # 改行コードを消去\n",
        "    text = re.sub('<br />', '', text)\n",
        "\n",
        "    # カンマ、ピリオド以外の記号をスペースに置換\n",
        "    for p in string.punctuation:\n",
        "        if (p == \".\") or (p == \",\"):\n",
        "            continue\n",
        "        else:\n",
        "            text = text.replace(p, \" \")\n",
        "\n",
        "    # ピリオドなどの前後にはスペースを入れておく\n",
        "    text = text.replace(\".\", \" . \")\n",
        "    text = text.replace(\",\", \" , \")\n",
        "    return text\n",
        "\n",
        "\n",
        "# 単語分割用のTokenizerを用意\n",
        "tokenizer_bert = BertTokenizer(\n",
        "    vocab_file=\"./vocab/bert-base-uncased-vocab.txt\", do_lower_case=True)\n",
        "\n",
        "\n",
        "# 前処理と単語分割をまとめた関数を定義\n",
        "# 単語分割の関数を渡すので、tokenizer_bertではなく、tokenizer_bert.tokenizeを渡す点に注意\n",
        "def tokenizer_with_preprocessing(text, tokenizer=tokenizer_bert.tokenize):\n",
        "    text = preprocessing_text(text)\n",
        "    ret = tokenizer(text)  # tokenizer_bert\n",
        "    return ret"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwpAFgTcRlHr",
        "outputId": "e347f9f4-4807-4fba-827e-99f254b03b18"
      },
      "source": [
        "# 動作テスト\n",
        "print(tokenizer_with_preprocessing(\"I fought the law, and the law won.\"))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'fought', 'the', 'law', ',', 'and', 'the', 'law', 'won', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSeAprh0tVOx"
      },
      "source": [
        "# データを読み込んだときに、読み込んだ内容に対して行う処理を定義\n",
        "max_length = 150\n",
        "\n",
        "#TEXT = torchtext.data.Field(sequential=True, tokenize=tokenizer_with_preprocessing, use_vocab=True,\n",
        "TEXT = data.Field(sequential=True, tokenize=tokenizer_with_preprocessing, use_vocab=True,\n",
        "                  lower=True, include_lengths=True, batch_first=True, fix_length=max_length, init_token=\"[CLS]\", eos_token=\"[SEP]\", pad_token='[PAD]', unk_token='[UNK]')\n",
        "#LABEL = torchtext.data.Field(sequential=False, use_vocab=False)\n",
        "LABEL = data.Field(sequential=False, use_vocab=False)\n",
        "# (注釈)：各引数を再確認\n",
        "# sequential: データの長さが可変か？文章は長さがいろいろなのでTrue.ラベルはFalse\n",
        "# tokenize: 文章を読み込んだときに、前処理や単語分割をするための関数を定義\n",
        "# use_vocab：単語をボキャブラリーに追加するかどうか\n",
        "# lower：アルファベットがあったときに小文字に変換するかどうか\n",
        "# include_length: 文章の単語数のデータを保持するか\n",
        "# batch_first：ミニバッチの次元を先頭に用意するかどうか\n",
        "# fix_length：全部の文章を指定した長さと同じになるように、paddingします\n",
        "# init_token, eos_token, pad_token, unk_token：文頭、文末、padding、未知語に対して、どんな単語を与えるかを指定\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3tY5d7WG6f9"
      },
      "source": [
        "#df = pd.read_table('data/training.tsv', header=0)\n",
        "df = pd.read_table('data/test.tsv', header=0)\n",
        "\n",
        "#df_out = df[[\"sentence\", \"label\"]]\n",
        "df_out = df[[\"sentence\"]]\n",
        "\n",
        "#df_out.to_csv(\"data/GAIC_training.tsv\", header=False, index=False, sep='\\t')\n",
        "df_out.to_csv(\"data/GAIC_test.tsv\", header=False, index=False, sep='\\t')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wr6Dv6UuGGjQ"
      },
      "source": [
        "# フォルダ「data」から各tsvファイルを読み込み\n",
        "\n",
        "#train_val_ds, test_ds = torchtext.data.TabularDataset.splits(\n",
        "train_val_ds, test_ds = data.TabularDataset.splits(\n",
        "    path='./data/', train='GAIC_training.tsv',\n",
        "    test='GAIC_test.tsv', format='tsv',\n",
        "    fields=[('Text', TEXT), ('Label', LABEL)])\n",
        "\n",
        "# torchtext.data.Datasetのsplit関数で訓練データとvalidationデータを分ける\n",
        "train_ds, val_ds = train_val_ds.split(\n",
        "    split_ratio=0.8, random_state=random.seed(1234))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-2am6TkIeiu"
      },
      "source": [
        "# https://qiita.com/itok_msi/items/1f3746f7e89a19dafac5\n",
        "\n",
        "# BERTはBERTが持つ全単語でBertEmbeddingモジュールを作成しているので、ボキャブラリーとしては全単語を使用\n",
        "# そのため訓練データからボキャブラリーは作成しない\n",
        "\n",
        "# まずBERT用の単語辞書を辞書型変数に用意します\n",
        "from utils.bert import BertTokenizer, load_vocab\n",
        "\n",
        "vocab_bert, ids_to_tokens_bert = load_vocab(\n",
        "#    vocab_file=\"./vocab/bert-base-uncased-vocab.txt\")\n",
        "    vocab_file=\"./vocab/bert-base-uncased-vocab_add_unk.txt\")\n",
        "\n",
        "# このまま、TEXT.vocab.stoi= vocab_bert (stoiはstring_to_IDで、単語からIDへの辞書)としたいですが、\n",
        "# 一度bulild_vocabを実行しないとTEXTオブジェクトがvocabのメンバ変数をもってくれないです。\n",
        "# （'Field' object has no attribute 'vocab' というエラーをはきます）\n",
        "\n",
        "# 1度適当にbuild_vocabでボキャブラリーを作成してから、BERTのボキャブラリーを上書きします\n",
        "TEXT.build_vocab(train_ds, min_freq=1)\n",
        "TEXT.vocab.stoi = vocab_bert\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QS4jPd9dZHdQ"
      },
      "source": [
        "# 辞書に登録された単語数\n",
        "len(TEXT.vocab.itos)#[\"[UNK]\"]\n",
        "TEXT.vocab.itos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O-17myeIpCI"
      },
      "source": [
        "# DataLoaderを作成します（torchtextの文脈では単純にiteraterと呼ばれています）\n",
        "batch_size = 32  # BERTでは16、32あたりを使用する\n",
        "\n",
        "#train_dl = torchtext.data.Iterator(\n",
        "train_dl = data.Iterator(\n",
        "    train_ds, batch_size=batch_size, train=True)\n",
        "\n",
        "#val_dl = torchtext.data.Iterator(\n",
        "val_dl = data.Iterator(\n",
        "    val_ds, batch_size=batch_size, train=False, sort=False)\n",
        "\n",
        "#test_dl = torchtext.data.Iterator(\n",
        "test_dl = data.Iterator(\n",
        "    test_ds, batch_size=batch_size, train=False, sort=False)\n",
        "\n",
        "# 辞書オブジェクトにまとめる\n",
        "dataloaders_dict = {\"train\": train_dl, \"val\": val_dl}\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LPyd5_vKc0r",
        "outputId": "103a277d-3889-4c88-a803-ac77deb99366"
      },
      "source": [
        "num_text = []\n",
        "for example in train_ds:\n",
        "        #print(example.Text, example.Label)\n",
        "        num_text.append(len(example.Text))\n",
        "print(\"max length : \", max(num_text))\n",
        "print(\"max_length index : \", num_text.index(max(num_text)))\n",
        "print(\"unique label\", set(train_ds.Label))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max length :  834\n",
            "max_length index :  6951\n",
            "unique label {'0', '1', '2', '3'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zADYVhAIxyY",
        "outputId": "12a830ae-bfdc-48d8-ec47-0deae30856d8"
      },
      "source": [
        "# 動作確認 検証データのデータセットで確認\n",
        "batch = next(iter(val_dl))\n",
        "print(batch.Text)\n",
        "print(batch.Label)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[ 101, 3422, 6495,  ...,    0,    0,    0],\n",
            "        [ 101, 1015, 2005,  ...,    0,    0,    0],\n",
            "        [ 101, 2433, 2184,  ...,    0,    0,    0],\n",
            "        ...,\n",
            "        [ 101, 2065, 2151,  ...,    0,    0,    0],\n",
            "        [ 101, 3964, 2000,  ...,    0,    0,    0],\n",
            "        [ 101, 1996, 2194,  ...,    0,    0,    0]]), tensor([18, 36,  6, 79, 35, 36, 37, 21, 36, 49, 30, 99,  5, 45, 29, 12, 61, 60,\n",
            "        26, 28, 36, 66,  5, 13, 30, 26, 33, 28, 46, 51,  7, 38]))\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        3, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnOcehUgQ4Ww",
        "outputId": "7ece87d1-0b4d-461b-b127-654b4e09c56c"
      },
      "source": [
        "#Text の次元数：(batch_size, fix_length:文章長さ) \n",
        "print(batch.Text[0].shape)\n",
        "print(batch.Text[1].shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 150])\n",
            "torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5wHJ92dyU-o",
        "outputId": "b5815455-d241-4763-9b66-c5bf423a3693"
      },
      "source": [
        "# ミニバッチの1文目を確認してみる\n",
        "text_minibatch_1 = (batch.Text[0][1]).numpy()\n",
        "\n",
        "# IDを単語に戻す\n",
        "text = tokenizer_bert.convert_ids_to_tokens(text_minibatch_1)\n",
        "\n",
        "print(text)\n",
        "print(len(text))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', '1', 'for', 'more', 'detailed', 'information', 'about', 'the', 'financial', 'derivatives', 'in', 'our', 'portfolio', ',', 'please', 'refer', 'to', 'note', '8', 'of', 'the', 'notes', 'to', 'consolidated', 'financial', 'statements', 'for', 'the', 'year', 'ended', 'december', '31', ',', '2019', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
            "150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbAFkB0W3RJM"
      },
      "source": [
        "# 感情分析用のBERTモデルを構築"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71EPz0GSyYsq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac5e1395-088a-4b20-9169-34b117696307"
      },
      "source": [
        "from utils.bert import get_config, BertModel, set_learned_params\n",
        "\n",
        "# モデル設定のJOSNファイルをオブジェクト変数として読み込みます\n",
        "config = get_config(file_path=\"./weights/bert_config.json\")\n",
        "\n",
        "# BERTモデルを作成します\n",
        "net_bert = BertModel(config)\n",
        "\n",
        "# BERTモデルに学習済みパラメータセットします\n",
        "net_bert = set_learned_params(\n",
        "    net_bert, weights_path=\"./weights/pytorch_model.bin\")\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert.embeddings.word_embeddings.weight→embeddings.word_embeddings.weight\n",
            "bert.embeddings.position_embeddings.weight→embeddings.position_embeddings.weight\n",
            "bert.embeddings.token_type_embeddings.weight→embeddings.token_type_embeddings.weight\n",
            "bert.embeddings.LayerNorm.gamma→embeddings.LayerNorm.gamma\n",
            "bert.embeddings.LayerNorm.beta→embeddings.LayerNorm.beta\n",
            "bert.encoder.layer.0.attention.self.query.weight→encoder.layer.0.attention.selfattn.query.weight\n",
            "bert.encoder.layer.0.attention.self.query.bias→encoder.layer.0.attention.selfattn.query.bias\n",
            "bert.encoder.layer.0.attention.self.key.weight→encoder.layer.0.attention.selfattn.key.weight\n",
            "bert.encoder.layer.0.attention.self.key.bias→encoder.layer.0.attention.selfattn.key.bias\n",
            "bert.encoder.layer.0.attention.self.value.weight→encoder.layer.0.attention.selfattn.value.weight\n",
            "bert.encoder.layer.0.attention.self.value.bias→encoder.layer.0.attention.selfattn.value.bias\n",
            "bert.encoder.layer.0.attention.output.dense.weight→encoder.layer.0.attention.output.dense.weight\n",
            "bert.encoder.layer.0.attention.output.dense.bias→encoder.layer.0.attention.output.dense.bias\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.gamma→encoder.layer.0.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.beta→encoder.layer.0.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.0.intermediate.dense.weight→encoder.layer.0.intermediate.dense.weight\n",
            "bert.encoder.layer.0.intermediate.dense.bias→encoder.layer.0.intermediate.dense.bias\n",
            "bert.encoder.layer.0.output.dense.weight→encoder.layer.0.output.dense.weight\n",
            "bert.encoder.layer.0.output.dense.bias→encoder.layer.0.output.dense.bias\n",
            "bert.encoder.layer.0.output.LayerNorm.gamma→encoder.layer.0.output.LayerNorm.gamma\n",
            "bert.encoder.layer.0.output.LayerNorm.beta→encoder.layer.0.output.LayerNorm.beta\n",
            "bert.encoder.layer.1.attention.self.query.weight→encoder.layer.1.attention.selfattn.query.weight\n",
            "bert.encoder.layer.1.attention.self.query.bias→encoder.layer.1.attention.selfattn.query.bias\n",
            "bert.encoder.layer.1.attention.self.key.weight→encoder.layer.1.attention.selfattn.key.weight\n",
            "bert.encoder.layer.1.attention.self.key.bias→encoder.layer.1.attention.selfattn.key.bias\n",
            "bert.encoder.layer.1.attention.self.value.weight→encoder.layer.1.attention.selfattn.value.weight\n",
            "bert.encoder.layer.1.attention.self.value.bias→encoder.layer.1.attention.selfattn.value.bias\n",
            "bert.encoder.layer.1.attention.output.dense.weight→encoder.layer.1.attention.output.dense.weight\n",
            "bert.encoder.layer.1.attention.output.dense.bias→encoder.layer.1.attention.output.dense.bias\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.gamma→encoder.layer.1.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.beta→encoder.layer.1.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.1.intermediate.dense.weight→encoder.layer.1.intermediate.dense.weight\n",
            "bert.encoder.layer.1.intermediate.dense.bias→encoder.layer.1.intermediate.dense.bias\n",
            "bert.encoder.layer.1.output.dense.weight→encoder.layer.1.output.dense.weight\n",
            "bert.encoder.layer.1.output.dense.bias→encoder.layer.1.output.dense.bias\n",
            "bert.encoder.layer.1.output.LayerNorm.gamma→encoder.layer.1.output.LayerNorm.gamma\n",
            "bert.encoder.layer.1.output.LayerNorm.beta→encoder.layer.1.output.LayerNorm.beta\n",
            "bert.encoder.layer.2.attention.self.query.weight→encoder.layer.2.attention.selfattn.query.weight\n",
            "bert.encoder.layer.2.attention.self.query.bias→encoder.layer.2.attention.selfattn.query.bias\n",
            "bert.encoder.layer.2.attention.self.key.weight→encoder.layer.2.attention.selfattn.key.weight\n",
            "bert.encoder.layer.2.attention.self.key.bias→encoder.layer.2.attention.selfattn.key.bias\n",
            "bert.encoder.layer.2.attention.self.value.weight→encoder.layer.2.attention.selfattn.value.weight\n",
            "bert.encoder.layer.2.attention.self.value.bias→encoder.layer.2.attention.selfattn.value.bias\n",
            "bert.encoder.layer.2.attention.output.dense.weight→encoder.layer.2.attention.output.dense.weight\n",
            "bert.encoder.layer.2.attention.output.dense.bias→encoder.layer.2.attention.output.dense.bias\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.gamma→encoder.layer.2.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.beta→encoder.layer.2.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.2.intermediate.dense.weight→encoder.layer.2.intermediate.dense.weight\n",
            "bert.encoder.layer.2.intermediate.dense.bias→encoder.layer.2.intermediate.dense.bias\n",
            "bert.encoder.layer.2.output.dense.weight→encoder.layer.2.output.dense.weight\n",
            "bert.encoder.layer.2.output.dense.bias→encoder.layer.2.output.dense.bias\n",
            "bert.encoder.layer.2.output.LayerNorm.gamma→encoder.layer.2.output.LayerNorm.gamma\n",
            "bert.encoder.layer.2.output.LayerNorm.beta→encoder.layer.2.output.LayerNorm.beta\n",
            "bert.encoder.layer.3.attention.self.query.weight→encoder.layer.3.attention.selfattn.query.weight\n",
            "bert.encoder.layer.3.attention.self.query.bias→encoder.layer.3.attention.selfattn.query.bias\n",
            "bert.encoder.layer.3.attention.self.key.weight→encoder.layer.3.attention.selfattn.key.weight\n",
            "bert.encoder.layer.3.attention.self.key.bias→encoder.layer.3.attention.selfattn.key.bias\n",
            "bert.encoder.layer.3.attention.self.value.weight→encoder.layer.3.attention.selfattn.value.weight\n",
            "bert.encoder.layer.3.attention.self.value.bias→encoder.layer.3.attention.selfattn.value.bias\n",
            "bert.encoder.layer.3.attention.output.dense.weight→encoder.layer.3.attention.output.dense.weight\n",
            "bert.encoder.layer.3.attention.output.dense.bias→encoder.layer.3.attention.output.dense.bias\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.gamma→encoder.layer.3.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.beta→encoder.layer.3.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.3.intermediate.dense.weight→encoder.layer.3.intermediate.dense.weight\n",
            "bert.encoder.layer.3.intermediate.dense.bias→encoder.layer.3.intermediate.dense.bias\n",
            "bert.encoder.layer.3.output.dense.weight→encoder.layer.3.output.dense.weight\n",
            "bert.encoder.layer.3.output.dense.bias→encoder.layer.3.output.dense.bias\n",
            "bert.encoder.layer.3.output.LayerNorm.gamma→encoder.layer.3.output.LayerNorm.gamma\n",
            "bert.encoder.layer.3.output.LayerNorm.beta→encoder.layer.3.output.LayerNorm.beta\n",
            "bert.encoder.layer.4.attention.self.query.weight→encoder.layer.4.attention.selfattn.query.weight\n",
            "bert.encoder.layer.4.attention.self.query.bias→encoder.layer.4.attention.selfattn.query.bias\n",
            "bert.encoder.layer.4.attention.self.key.weight→encoder.layer.4.attention.selfattn.key.weight\n",
            "bert.encoder.layer.4.attention.self.key.bias→encoder.layer.4.attention.selfattn.key.bias\n",
            "bert.encoder.layer.4.attention.self.value.weight→encoder.layer.4.attention.selfattn.value.weight\n",
            "bert.encoder.layer.4.attention.self.value.bias→encoder.layer.4.attention.selfattn.value.bias\n",
            "bert.encoder.layer.4.attention.output.dense.weight→encoder.layer.4.attention.output.dense.weight\n",
            "bert.encoder.layer.4.attention.output.dense.bias→encoder.layer.4.attention.output.dense.bias\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.gamma→encoder.layer.4.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.beta→encoder.layer.4.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.4.intermediate.dense.weight→encoder.layer.4.intermediate.dense.weight\n",
            "bert.encoder.layer.4.intermediate.dense.bias→encoder.layer.4.intermediate.dense.bias\n",
            "bert.encoder.layer.4.output.dense.weight→encoder.layer.4.output.dense.weight\n",
            "bert.encoder.layer.4.output.dense.bias→encoder.layer.4.output.dense.bias\n",
            "bert.encoder.layer.4.output.LayerNorm.gamma→encoder.layer.4.output.LayerNorm.gamma\n",
            "bert.encoder.layer.4.output.LayerNorm.beta→encoder.layer.4.output.LayerNorm.beta\n",
            "bert.encoder.layer.5.attention.self.query.weight→encoder.layer.5.attention.selfattn.query.weight\n",
            "bert.encoder.layer.5.attention.self.query.bias→encoder.layer.5.attention.selfattn.query.bias\n",
            "bert.encoder.layer.5.attention.self.key.weight→encoder.layer.5.attention.selfattn.key.weight\n",
            "bert.encoder.layer.5.attention.self.key.bias→encoder.layer.5.attention.selfattn.key.bias\n",
            "bert.encoder.layer.5.attention.self.value.weight→encoder.layer.5.attention.selfattn.value.weight\n",
            "bert.encoder.layer.5.attention.self.value.bias→encoder.layer.5.attention.selfattn.value.bias\n",
            "bert.encoder.layer.5.attention.output.dense.weight→encoder.layer.5.attention.output.dense.weight\n",
            "bert.encoder.layer.5.attention.output.dense.bias→encoder.layer.5.attention.output.dense.bias\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.gamma→encoder.layer.5.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.beta→encoder.layer.5.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.5.intermediate.dense.weight→encoder.layer.5.intermediate.dense.weight\n",
            "bert.encoder.layer.5.intermediate.dense.bias→encoder.layer.5.intermediate.dense.bias\n",
            "bert.encoder.layer.5.output.dense.weight→encoder.layer.5.output.dense.weight\n",
            "bert.encoder.layer.5.output.dense.bias→encoder.layer.5.output.dense.bias\n",
            "bert.encoder.layer.5.output.LayerNorm.gamma→encoder.layer.5.output.LayerNorm.gamma\n",
            "bert.encoder.layer.5.output.LayerNorm.beta→encoder.layer.5.output.LayerNorm.beta\n",
            "bert.encoder.layer.6.attention.self.query.weight→encoder.layer.6.attention.selfattn.query.weight\n",
            "bert.encoder.layer.6.attention.self.query.bias→encoder.layer.6.attention.selfattn.query.bias\n",
            "bert.encoder.layer.6.attention.self.key.weight→encoder.layer.6.attention.selfattn.key.weight\n",
            "bert.encoder.layer.6.attention.self.key.bias→encoder.layer.6.attention.selfattn.key.bias\n",
            "bert.encoder.layer.6.attention.self.value.weight→encoder.layer.6.attention.selfattn.value.weight\n",
            "bert.encoder.layer.6.attention.self.value.bias→encoder.layer.6.attention.selfattn.value.bias\n",
            "bert.encoder.layer.6.attention.output.dense.weight→encoder.layer.6.attention.output.dense.weight\n",
            "bert.encoder.layer.6.attention.output.dense.bias→encoder.layer.6.attention.output.dense.bias\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.gamma→encoder.layer.6.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.beta→encoder.layer.6.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.6.intermediate.dense.weight→encoder.layer.6.intermediate.dense.weight\n",
            "bert.encoder.layer.6.intermediate.dense.bias→encoder.layer.6.intermediate.dense.bias\n",
            "bert.encoder.layer.6.output.dense.weight→encoder.layer.6.output.dense.weight\n",
            "bert.encoder.layer.6.output.dense.bias→encoder.layer.6.output.dense.bias\n",
            "bert.encoder.layer.6.output.LayerNorm.gamma→encoder.layer.6.output.LayerNorm.gamma\n",
            "bert.encoder.layer.6.output.LayerNorm.beta→encoder.layer.6.output.LayerNorm.beta\n",
            "bert.encoder.layer.7.attention.self.query.weight→encoder.layer.7.attention.selfattn.query.weight\n",
            "bert.encoder.layer.7.attention.self.query.bias→encoder.layer.7.attention.selfattn.query.bias\n",
            "bert.encoder.layer.7.attention.self.key.weight→encoder.layer.7.attention.selfattn.key.weight\n",
            "bert.encoder.layer.7.attention.self.key.bias→encoder.layer.7.attention.selfattn.key.bias\n",
            "bert.encoder.layer.7.attention.self.value.weight→encoder.layer.7.attention.selfattn.value.weight\n",
            "bert.encoder.layer.7.attention.self.value.bias→encoder.layer.7.attention.selfattn.value.bias\n",
            "bert.encoder.layer.7.attention.output.dense.weight→encoder.layer.7.attention.output.dense.weight\n",
            "bert.encoder.layer.7.attention.output.dense.bias→encoder.layer.7.attention.output.dense.bias\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.gamma→encoder.layer.7.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.beta→encoder.layer.7.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.7.intermediate.dense.weight→encoder.layer.7.intermediate.dense.weight\n",
            "bert.encoder.layer.7.intermediate.dense.bias→encoder.layer.7.intermediate.dense.bias\n",
            "bert.encoder.layer.7.output.dense.weight→encoder.layer.7.output.dense.weight\n",
            "bert.encoder.layer.7.output.dense.bias→encoder.layer.7.output.dense.bias\n",
            "bert.encoder.layer.7.output.LayerNorm.gamma→encoder.layer.7.output.LayerNorm.gamma\n",
            "bert.encoder.layer.7.output.LayerNorm.beta→encoder.layer.7.output.LayerNorm.beta\n",
            "bert.encoder.layer.8.attention.self.query.weight→encoder.layer.8.attention.selfattn.query.weight\n",
            "bert.encoder.layer.8.attention.self.query.bias→encoder.layer.8.attention.selfattn.query.bias\n",
            "bert.encoder.layer.8.attention.self.key.weight→encoder.layer.8.attention.selfattn.key.weight\n",
            "bert.encoder.layer.8.attention.self.key.bias→encoder.layer.8.attention.selfattn.key.bias\n",
            "bert.encoder.layer.8.attention.self.value.weight→encoder.layer.8.attention.selfattn.value.weight\n",
            "bert.encoder.layer.8.attention.self.value.bias→encoder.layer.8.attention.selfattn.value.bias\n",
            "bert.encoder.layer.8.attention.output.dense.weight→encoder.layer.8.attention.output.dense.weight\n",
            "bert.encoder.layer.8.attention.output.dense.bias→encoder.layer.8.attention.output.dense.bias\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.gamma→encoder.layer.8.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.beta→encoder.layer.8.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.8.intermediate.dense.weight→encoder.layer.8.intermediate.dense.weight\n",
            "bert.encoder.layer.8.intermediate.dense.bias→encoder.layer.8.intermediate.dense.bias\n",
            "bert.encoder.layer.8.output.dense.weight→encoder.layer.8.output.dense.weight\n",
            "bert.encoder.layer.8.output.dense.bias→encoder.layer.8.output.dense.bias\n",
            "bert.encoder.layer.8.output.LayerNorm.gamma→encoder.layer.8.output.LayerNorm.gamma\n",
            "bert.encoder.layer.8.output.LayerNorm.beta→encoder.layer.8.output.LayerNorm.beta\n",
            "bert.encoder.layer.9.attention.self.query.weight→encoder.layer.9.attention.selfattn.query.weight\n",
            "bert.encoder.layer.9.attention.self.query.bias→encoder.layer.9.attention.selfattn.query.bias\n",
            "bert.encoder.layer.9.attention.self.key.weight→encoder.layer.9.attention.selfattn.key.weight\n",
            "bert.encoder.layer.9.attention.self.key.bias→encoder.layer.9.attention.selfattn.key.bias\n",
            "bert.encoder.layer.9.attention.self.value.weight→encoder.layer.9.attention.selfattn.value.weight\n",
            "bert.encoder.layer.9.attention.self.value.bias→encoder.layer.9.attention.selfattn.value.bias\n",
            "bert.encoder.layer.9.attention.output.dense.weight→encoder.layer.9.attention.output.dense.weight\n",
            "bert.encoder.layer.9.attention.output.dense.bias→encoder.layer.9.attention.output.dense.bias\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.gamma→encoder.layer.9.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.beta→encoder.layer.9.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.9.intermediate.dense.weight→encoder.layer.9.intermediate.dense.weight\n",
            "bert.encoder.layer.9.intermediate.dense.bias→encoder.layer.9.intermediate.dense.bias\n",
            "bert.encoder.layer.9.output.dense.weight→encoder.layer.9.output.dense.weight\n",
            "bert.encoder.layer.9.output.dense.bias→encoder.layer.9.output.dense.bias\n",
            "bert.encoder.layer.9.output.LayerNorm.gamma→encoder.layer.9.output.LayerNorm.gamma\n",
            "bert.encoder.layer.9.output.LayerNorm.beta→encoder.layer.9.output.LayerNorm.beta\n",
            "bert.encoder.layer.10.attention.self.query.weight→encoder.layer.10.attention.selfattn.query.weight\n",
            "bert.encoder.layer.10.attention.self.query.bias→encoder.layer.10.attention.selfattn.query.bias\n",
            "bert.encoder.layer.10.attention.self.key.weight→encoder.layer.10.attention.selfattn.key.weight\n",
            "bert.encoder.layer.10.attention.self.key.bias→encoder.layer.10.attention.selfattn.key.bias\n",
            "bert.encoder.layer.10.attention.self.value.weight→encoder.layer.10.attention.selfattn.value.weight\n",
            "bert.encoder.layer.10.attention.self.value.bias→encoder.layer.10.attention.selfattn.value.bias\n",
            "bert.encoder.layer.10.attention.output.dense.weight→encoder.layer.10.attention.output.dense.weight\n",
            "bert.encoder.layer.10.attention.output.dense.bias→encoder.layer.10.attention.output.dense.bias\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.gamma→encoder.layer.10.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.beta→encoder.layer.10.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.10.intermediate.dense.weight→encoder.layer.10.intermediate.dense.weight\n",
            "bert.encoder.layer.10.intermediate.dense.bias→encoder.layer.10.intermediate.dense.bias\n",
            "bert.encoder.layer.10.output.dense.weight→encoder.layer.10.output.dense.weight\n",
            "bert.encoder.layer.10.output.dense.bias→encoder.layer.10.output.dense.bias\n",
            "bert.encoder.layer.10.output.LayerNorm.gamma→encoder.layer.10.output.LayerNorm.gamma\n",
            "bert.encoder.layer.10.output.LayerNorm.beta→encoder.layer.10.output.LayerNorm.beta\n",
            "bert.encoder.layer.11.attention.self.query.weight→encoder.layer.11.attention.selfattn.query.weight\n",
            "bert.encoder.layer.11.attention.self.query.bias→encoder.layer.11.attention.selfattn.query.bias\n",
            "bert.encoder.layer.11.attention.self.key.weight→encoder.layer.11.attention.selfattn.key.weight\n",
            "bert.encoder.layer.11.attention.self.key.bias→encoder.layer.11.attention.selfattn.key.bias\n",
            "bert.encoder.layer.11.attention.self.value.weight→encoder.layer.11.attention.selfattn.value.weight\n",
            "bert.encoder.layer.11.attention.self.value.bias→encoder.layer.11.attention.selfattn.value.bias\n",
            "bert.encoder.layer.11.attention.output.dense.weight→encoder.layer.11.attention.output.dense.weight\n",
            "bert.encoder.layer.11.attention.output.dense.bias→encoder.layer.11.attention.output.dense.bias\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.gamma→encoder.layer.11.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.beta→encoder.layer.11.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.11.intermediate.dense.weight→encoder.layer.11.intermediate.dense.weight\n",
            "bert.encoder.layer.11.intermediate.dense.bias→encoder.layer.11.intermediate.dense.bias\n",
            "bert.encoder.layer.11.output.dense.weight→encoder.layer.11.output.dense.weight\n",
            "bert.encoder.layer.11.output.dense.bias→encoder.layer.11.output.dense.bias\n",
            "bert.encoder.layer.11.output.LayerNorm.gamma→encoder.layer.11.output.LayerNorm.gamma\n",
            "bert.encoder.layer.11.output.LayerNorm.beta→encoder.layer.11.output.LayerNorm.beta\n",
            "bert.pooler.dense.weight→pooler.dense.weight\n",
            "bert.pooler.dense.bias→pooler.dense.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YA3Y5i43lxp"
      },
      "source": [
        "class BertForGAIC(nn.Module):\n",
        "    '''BERTモデルにGlobalAIChallengeのラベルを判定する部分をつなげたモデル'''\n",
        "\n",
        "    def __init__(self, net_bert):\n",
        "        super(BertForGAIC, self).__init__()\n",
        "\n",
        "        # BERTモジュール\n",
        "        self.bert = net_bert  # BERTモデル\n",
        "\n",
        "        # headにLabel予測を追加\n",
        "        # 入力はBERTの出力特徴量の次元、出力はLabelの4つ\n",
        "        self.cls = nn.Linear(in_features=768, out_features=4)\n",
        "\n",
        "        # 重み初期化処理\n",
        "        nn.init.normal_(self.cls.weight, std=0.02)\n",
        "        nn.init.normal_(self.cls.bias, 0)\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, output_all_encoded_layers=False, attention_show_flg=False):\n",
        "        '''\n",
        "        input_ids： [batch_size, sequence_length]の文章の単語IDの羅列\n",
        "        token_type_ids： [batch_size, sequence_length]の、各単語が1文目なのか、2文目なのかを示すid\n",
        "        attention_mask：Transformerのマスクと同じ働きのマスキングです\n",
        "        output_all_encoded_layers：最終出力に12段のTransformerの全部をリストで返すか、最後だけかを指定\n",
        "        attention_show_flg：Self-Attentionの重みを返すかのフラグ\n",
        "        '''\n",
        "\n",
        "        # BERTの基本モデル部分の順伝搬\n",
        "        # 順伝搬させる\n",
        "        if attention_show_flg == True:\n",
        "            '''attention_showのときは、attention_probsもリターンする'''\n",
        "            encoded_layers, pooled_output, attention_probs = self.bert(\n",
        "                input_ids, token_type_ids, attention_mask, output_all_encoded_layers, attention_show_flg)\n",
        "        elif attention_show_flg == False:\n",
        "            encoded_layers, pooled_output = self.bert(\n",
        "                input_ids, token_type_ids, attention_mask, output_all_encoded_layers, attention_show_flg)\n",
        "\n",
        "        # 入力文章の1単語目[CLS]の特徴量を使用して、Labelを分類\n",
        "        vec_0 = encoded_layers[:, 0, :]\n",
        "        vec_0 = vec_0.view(-1, 768)  # sizeを[batch_size, hidden_sizeに変換\n",
        "        out = self.cls(vec_0)\n",
        "\n",
        "        # attention_showのときは、attention_probs（1番最後の）もリターンする\n",
        "        if attention_show_flg == True:\n",
        "            return out, attention_probs\n",
        "        elif attention_show_flg == False:\n",
        "            return out"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4I8jExZ5m0s",
        "outputId": "ad71793e-91bd-4330-b6d4-1fee53925961"
      },
      "source": [
        "# モデル構築\n",
        "net = BertForGAIC(net_bert)\n",
        "\n",
        "# 訓練モードに設定\n",
        "net.train()\n",
        "\n",
        "print('ネットワーク設定完了')\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ネットワーク設定完了\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1nahmiI5_Q1"
      },
      "source": [
        "#BERTのファインチューニングに向けた設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW19j79Q5tId"
      },
      "source": [
        "# 勾配計算を最後のBertLayerモジュールと追加した分類アダプターのみ実行\n",
        "\n",
        "# 1. まず全部を、勾配計算Falseにしてしまう\n",
        "for name, param in net.named_parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# 2. 最後のBertLayerモジュールを勾配計算ありに変更\n",
        "for name, param in net.bert.encoder.layer[-1].named_parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# 3. 識別器を勾配計算ありに変更\n",
        "for name, param in net.cls.named_parameters():\n",
        "    param.requires_grad = True\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWPepaG56Dbs"
      },
      "source": [
        "# 最適化手法の設定\n",
        "\n",
        "# BERTの元の部分はファインチューニング\n",
        "optimizer = optim.Adam([\n",
        "    {'params': net.bert.encoder.layer[-1].parameters(), 'lr': 5e-5},\n",
        "    {'params': net.cls.parameters(), 'lr': 5e-5}\n",
        "], betas=(0.9, 0.999))\n",
        "\n",
        "# 損失関数の設定\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# nn.LogSoftmax()を計算してからnn.NLLLoss(negative log likelihood loss)を計算"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Qooq5B36LIo"
      },
      "source": [
        "# 学習・検証を実施"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSkNkaFn6GgP"
      },
      "source": [
        "# モデルを学習させる関数を作成\n",
        "\n",
        "\n",
        "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
        "\n",
        "    # GPUが使えるかを確認\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"使用デバイス：\", device)\n",
        "    print('-----start-------')\n",
        "\n",
        "    # ネットワークをGPUへ\n",
        "    net.to(device)\n",
        "\n",
        "    # ネットワークがある程度固定であれば、高速化させる\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # ミニバッチのサイズ\n",
        "    batch_size = dataloaders_dict[\"train\"].batch_size\n",
        "\n",
        "    # epochのループ\n",
        "    for epoch in range(num_epochs):\n",
        "        # epochごとの訓練と検証のループ\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                net.train()  # モデルを訓練モードに\n",
        "            else:\n",
        "                net.eval()   # モデルを検証モードに\n",
        "\n",
        "            epoch_loss = 0.0  # epochの損失和\n",
        "            epoch_corrects = 0  # epochの正解数\n",
        "            iteration = 1\n",
        "\n",
        "            # 開始時刻を保存\n",
        "            t_epoch_start = time.time()\n",
        "            t_iter_start = time.time()\n",
        "\n",
        "            # データローダーからミニバッチを取り出すループ\n",
        "            for batch in (dataloaders_dict[phase]):\n",
        "                # batchはTextとLableの辞書型変数\n",
        "\n",
        "                # GPUが使えるならGPUにデータを送る\n",
        "                inputs = batch.Text[0].to(device)  # 文章\n",
        "                labels = batch.Label.to(device)  # ラベル\n",
        "\n",
        "                # optimizerを初期化\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # 順伝搬（forward）計算\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "\n",
        "                    # BertForGAICに入力\n",
        "                    outputs = net(inputs, token_type_ids=None, attention_mask=None,\n",
        "                                  output_all_encoded_layers=False, attention_show_flg=False)\n",
        "\n",
        "                    loss = criterion(outputs, labels)  # 損失を計算\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
        "\n",
        "                    # 訓練時はバックプロパゲーション\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                        if (iteration % 10 == 0):  # 10iterに1度、lossを表示\n",
        "                            t_iter_finish = time.time()\n",
        "                            duration = t_iter_finish - t_iter_start\n",
        "                            acc = (torch.sum(preds == labels.data)\n",
        "                                   ).double()/batch_size\n",
        "                            print('イテレーション {} || Loss: {:.4f} || 10iter: {:.4f} sec. || 本イテレーションの正解率：{}'.format(\n",
        "                                iteration, loss.item(), duration, acc))\n",
        "                            t_iter_start = time.time()\n",
        "\n",
        "                    iteration += 1\n",
        "\n",
        "                    # 損失と正解数の合計を更新\n",
        "                    epoch_loss += loss.item() * batch_size\n",
        "                    epoch_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            # epochごとのlossと正解率\n",
        "            t_epoch_finish = time.time()\n",
        "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
        "            epoch_acc = epoch_corrects.double(\n",
        "            ) / len(dataloaders_dict[phase].dataset)\n",
        "\n",
        "            print('Epoch {}/{} | {:^5} |  Loss: {:.4f} Acc: {:.4f}'.format(epoch+1, num_epochs,\n",
        "                                                                           phase, epoch_loss, epoch_acc))\n",
        "            t_epoch_start = time.time()\n",
        "\n",
        "    return net\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZj9uoYc6SBX",
        "outputId": "2aa13b5c-be1c-44b8-d80e-5c96e3f620f4"
      },
      "source": [
        "# 学習・検証を実行\n",
        "num_epochs = 2\n",
        "net_trained = train_model(net, dataloaders_dict,\n",
        "                          criterion, optimizer, num_epochs=num_epochs)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "使用デバイス： cuda:0\n",
            "-----start-------\n",
            "イテレーション 10 || Loss: 0.4091 || 10iter: 2.1245 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 20 || Loss: 0.0173 || 10iter: 1.9294 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 30 || Loss: 0.5115 || 10iter: 1.9280 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 40 || Loss: 0.1434 || 10iter: 1.9292 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 50 || Loss: 0.2477 || 10iter: 1.9280 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 60 || Loss: 0.1561 || 10iter: 1.9283 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 70 || Loss: 0.0342 || 10iter: 1.9292 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 80 || Loss: 0.0403 || 10iter: 1.9298 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 90 || Loss: 0.1493 || 10iter: 1.9282 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 100 || Loss: 0.0305 || 10iter: 1.9294 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 110 || Loss: 0.1458 || 10iter: 1.9321 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 120 || Loss: 0.1073 || 10iter: 1.9310 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 130 || Loss: 0.1566 || 10iter: 1.9346 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 140 || Loss: 0.2415 || 10iter: 1.9305 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 150 || Loss: 0.0479 || 10iter: 1.9300 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 160 || Loss: 0.0612 || 10iter: 1.9315 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 170 || Loss: 0.1406 || 10iter: 1.9299 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 180 || Loss: 0.2331 || 10iter: 1.9301 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 190 || Loss: 0.2028 || 10iter: 1.9351 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 200 || Loss: 0.0515 || 10iter: 1.9307 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 210 || Loss: 0.1325 || 10iter: 1.9304 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 220 || Loss: 0.0935 || 10iter: 1.9313 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 230 || Loss: 0.1971 || 10iter: 1.9304 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 240 || Loss: 0.2998 || 10iter: 1.9306 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 250 || Loss: 0.2600 || 10iter: 1.9293 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 260 || Loss: 0.1548 || 10iter: 1.9306 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 270 || Loss: 0.1472 || 10iter: 1.9306 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 280 || Loss: 0.1056 || 10iter: 1.9313 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 290 || Loss: 0.2404 || 10iter: 1.9303 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 300 || Loss: 0.1311 || 10iter: 1.9309 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 310 || Loss: 0.0995 || 10iter: 1.9307 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 320 || Loss: 0.1365 || 10iter: 1.9307 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 330 || Loss: 0.4154 || 10iter: 1.9372 sec. || 本イテレーションの正解率：0.84375\n",
            "イテレーション 340 || Loss: 0.0609 || 10iter: 1.9307 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 350 || Loss: 0.2505 || 10iter: 1.9304 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 360 || Loss: 0.1641 || 10iter: 1.9299 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 370 || Loss: 0.0160 || 10iter: 1.9320 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 380 || Loss: 0.2535 || 10iter: 1.9338 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 390 || Loss: 0.2634 || 10iter: 1.9336 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 400 || Loss: 0.0546 || 10iter: 1.9302 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 410 || Loss: 0.2104 || 10iter: 1.9354 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 420 || Loss: 0.2262 || 10iter: 1.9302 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 430 || Loss: 0.0546 || 10iter: 1.9304 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 440 || Loss: 0.0566 || 10iter: 1.9290 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 450 || Loss: 0.0946 || 10iter: 1.9298 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 460 || Loss: 0.3141 || 10iter: 1.9332 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 470 || Loss: 0.0887 || 10iter: 1.9308 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 480 || Loss: 0.2708 || 10iter: 1.9309 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 490 || Loss: 0.1677 || 10iter: 1.9305 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 500 || Loss: 0.2361 || 10iter: 1.9302 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 510 || Loss: 0.0797 || 10iter: 1.9324 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 520 || Loss: 0.2644 || 10iter: 1.9312 sec. || 本イテレーションの正解率：0.875\n",
            "イテレーション 530 || Loss: 0.1206 || 10iter: 1.9303 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 540 || Loss: 0.1217 || 10iter: 1.9329 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 550 || Loss: 0.0185 || 10iter: 1.9316 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 560 || Loss: 0.0487 || 10iter: 1.9302 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 570 || Loss: 0.2245 || 10iter: 1.9394 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 580 || Loss: 0.0736 || 10iter: 1.9295 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 590 || Loss: 0.2953 || 10iter: 1.9319 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 600 || Loss: 0.2649 || 10iter: 1.9292 sec. || 本イテレーションの正解率：0.875\n",
            "イテレーション 610 || Loss: 0.1389 || 10iter: 1.9304 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 620 || Loss: 0.1699 || 10iter: 1.9356 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 630 || Loss: 0.2937 || 10iter: 1.9308 sec. || 本イテレーションの正解率：0.875\n",
            "イテレーション 640 || Loss: 0.0455 || 10iter: 1.9302 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 650 || Loss: 0.6018 || 10iter: 1.9313 sec. || 本イテレーションの正解率：0.84375\n",
            "イテレーション 660 || Loss: 0.3875 || 10iter: 1.9310 sec. || 本イテレーションの正解率：0.84375\n",
            "イテレーション 670 || Loss: 0.0363 || 10iter: 1.9290 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 680 || Loss: 0.6715 || 10iter: 1.9296 sec. || 本イテレーションの正解率：0.875\n",
            "イテレーション 690 || Loss: 0.1484 || 10iter: 1.9333 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 700 || Loss: 0.1555 || 10iter: 1.9292 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 710 || Loss: 0.2568 || 10iter: 1.9304 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 720 || Loss: 0.3223 || 10iter: 1.9300 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 730 || Loss: 0.2366 || 10iter: 1.9310 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 740 || Loss: 0.0088 || 10iter: 1.9301 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 750 || Loss: 0.0289 || 10iter: 1.9304 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 760 || Loss: 0.2660 || 10iter: 1.9296 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 770 || Loss: 0.0535 || 10iter: 1.9333 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 780 || Loss: 0.3777 || 10iter: 1.9296 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 790 || Loss: 0.2827 || 10iter: 1.9287 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 800 || Loss: 0.0323 || 10iter: 1.9292 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 810 || Loss: 0.2490 || 10iter: 1.9281 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 820 || Loss: 0.1523 || 10iter: 1.9290 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 830 || Loss: 0.0326 || 10iter: 1.9295 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 840 || Loss: 0.2172 || 10iter: 1.9302 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 850 || Loss: 0.0304 || 10iter: 1.9310 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 860 || Loss: 0.3238 || 10iter: 1.9299 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 870 || Loss: 0.1770 || 10iter: 1.9299 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 880 || Loss: 0.1628 || 10iter: 1.9303 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 890 || Loss: 0.1820 || 10iter: 1.9302 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 900 || Loss: 0.0750 || 10iter: 1.9317 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 910 || Loss: 0.0525 || 10iter: 1.9308 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 920 || Loss: 0.1461 || 10iter: 1.9305 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 930 || Loss: 0.1030 || 10iter: 1.9333 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 940 || Loss: 0.0955 || 10iter: 1.9321 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 950 || Loss: 0.1727 || 10iter: 1.9325 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 960 || Loss: 0.2216 || 10iter: 1.9298 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 970 || Loss: 0.0961 || 10iter: 1.9303 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 980 || Loss: 0.1987 || 10iter: 1.9299 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 990 || Loss: 0.0142 || 10iter: 1.9297 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1000 || Loss: 0.0574 || 10iter: 1.9301 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1010 || Loss: 0.4086 || 10iter: 1.9309 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 1020 || Loss: 0.1389 || 10iter: 1.9347 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1030 || Loss: 0.0840 || 10iter: 1.9305 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1040 || Loss: 0.0559 || 10iter: 1.9320 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1050 || Loss: 0.1157 || 10iter: 1.9295 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1060 || Loss: 0.1812 || 10iter: 1.9297 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 1070 || Loss: 0.2911 || 10iter: 1.9292 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 1080 || Loss: 0.2809 || 10iter: 1.9295 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 1090 || Loss: 0.1814 || 10iter: 1.9295 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1100 || Loss: 0.0695 || 10iter: 1.9306 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1110 || Loss: 0.0829 || 10iter: 1.9350 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1120 || Loss: 0.0138 || 10iter: 1.9311 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1130 || Loss: 0.0629 || 10iter: 1.9293 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1140 || Loss: 0.1661 || 10iter: 1.9304 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 1150 || Loss: 0.2383 || 10iter: 1.9302 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1160 || Loss: 0.3133 || 10iter: 1.9291 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 1170 || Loss: 0.2310 || 10iter: 1.9302 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 1180 || Loss: 0.0537 || 10iter: 1.9288 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1190 || Loss: 0.0804 || 10iter: 1.9293 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1200 || Loss: 0.0424 || 10iter: 1.9298 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1210 || Loss: 0.0808 || 10iter: 1.9308 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1220 || Loss: 0.0770 || 10iter: 1.9295 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1230 || Loss: 0.0271 || 10iter: 1.9304 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1240 || Loss: 0.0476 || 10iter: 1.9291 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1250 || Loss: 0.2033 || 10iter: 1.9313 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 1260 || Loss: 0.0879 || 10iter: 1.9300 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1270 || Loss: 0.0100 || 10iter: 1.9298 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1280 || Loss: 0.0599 || 10iter: 1.9334 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1290 || Loss: 0.3665 || 10iter: 1.9338 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 1300 || Loss: 0.0614 || 10iter: 1.9290 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1310 || Loss: 0.2358 || 10iter: 1.9337 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1320 || Loss: 0.0826 || 10iter: 1.9357 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1330 || Loss: 0.0357 || 10iter: 1.9372 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1340 || Loss: 0.1034 || 10iter: 1.9297 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 1350 || Loss: 0.1722 || 10iter: 1.9303 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 1360 || Loss: 0.0351 || 10iter: 1.9310 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1370 || Loss: 0.0106 || 10iter: 1.9304 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1380 || Loss: 0.2399 || 10iter: 1.9302 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 1390 || Loss: 0.0387 || 10iter: 1.9309 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1400 || Loss: 0.0857 || 10iter: 1.9302 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1410 || Loss: 0.0144 || 10iter: 1.9305 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1420 || Loss: 0.0324 || 10iter: 1.9293 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1430 || Loss: 0.2584 || 10iter: 1.9328 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 1440 || Loss: 0.0168 || 10iter: 1.9289 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1450 || Loss: 0.1038 || 10iter: 1.9298 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 1460 || Loss: 0.1627 || 10iter: 1.9311 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 1470 || Loss: 0.2043 || 10iter: 1.9308 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 1480 || Loss: 0.2001 || 10iter: 1.9341 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1490 || Loss: 0.1615 || 10iter: 1.9311 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1500 || Loss: 0.3965 || 10iter: 1.9307 sec. || 本イテレーションの正解率：0.875\n",
            "イテレーション 1510 || Loss: 0.1430 || 10iter: 1.9354 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1520 || Loss: 0.3158 || 10iter: 1.9290 sec. || 本イテレーションの正解率：0.875\n",
            "イテレーション 1530 || Loss: 0.0656 || 10iter: 1.9322 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1540 || Loss: 0.2249 || 10iter: 1.9292 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 1550 || Loss: 0.0449 || 10iter: 1.9292 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1560 || Loss: 0.1719 || 10iter: 1.9313 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1570 || Loss: 0.0563 || 10iter: 1.9316 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1580 || Loss: 0.4262 || 10iter: 1.9297 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 1590 || Loss: 0.1100 || 10iter: 1.9297 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1600 || Loss: 0.2096 || 10iter: 1.9305 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 1610 || Loss: 0.2140 || 10iter: 1.9297 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1620 || Loss: 0.1366 || 10iter: 1.9292 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1630 || Loss: 0.1639 || 10iter: 1.9304 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1640 || Loss: 0.0353 || 10iter: 1.9312 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1650 || Loss: 0.0109 || 10iter: 1.9335 sec. || 本イテレーションの正解率：0.0625\n",
            "Epoch 1/2 | train |  Loss: 0.1581 Acc: 0.9569\n",
            "Epoch 1/2 |  val  |  Loss: 0.1192 Acc: 0.9643\n",
            "イテレーション 10 || Loss: 0.0123 || 10iter: 1.9923 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 20 || Loss: 0.0535 || 10iter: 1.9297 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 30 || Loss: 0.1796 || 10iter: 1.9302 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 40 || Loss: 0.1176 || 10iter: 1.9299 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 50 || Loss: 0.1764 || 10iter: 1.9299 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 60 || Loss: 0.3890 || 10iter: 1.9293 sec. || 本イテレーションの正解率：0.875\n",
            "イテレーション 70 || Loss: 0.0162 || 10iter: 1.9354 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 80 || Loss: 0.0248 || 10iter: 1.9291 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 90 || Loss: 0.0258 || 10iter: 1.9340 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 100 || Loss: 0.0577 || 10iter: 1.9365 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 110 || Loss: 0.0123 || 10iter: 1.9302 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 120 || Loss: 0.1691 || 10iter: 1.9302 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 130 || Loss: 0.1697 || 10iter: 1.9283 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 140 || Loss: 0.0675 || 10iter: 1.9302 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 150 || Loss: 0.1710 || 10iter: 1.9306 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 160 || Loss: 0.0176 || 10iter: 1.9360 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 170 || Loss: 0.0225 || 10iter: 1.9311 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 180 || Loss: 0.1583 || 10iter: 1.9362 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 190 || Loss: 0.1489 || 10iter: 1.9289 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 200 || Loss: 0.0342 || 10iter: 1.9304 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 210 || Loss: 0.1621 || 10iter: 1.9308 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 220 || Loss: 0.0908 || 10iter: 1.9321 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 230 || Loss: 0.0441 || 10iter: 1.9309 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 240 || Loss: 0.1853 || 10iter: 1.9308 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 250 || Loss: 0.1195 || 10iter: 1.9356 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 260 || Loss: 0.0192 || 10iter: 1.9293 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 270 || Loss: 0.4126 || 10iter: 1.9312 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 280 || Loss: 0.0304 || 10iter: 1.9294 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 290 || Loss: 0.2190 || 10iter: 1.9285 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 300 || Loss: 0.2136 || 10iter: 1.9300 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 310 || Loss: 0.0237 || 10iter: 1.9298 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 320 || Loss: 0.0392 || 10iter: 1.9302 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 330 || Loss: 0.0199 || 10iter: 1.9291 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 340 || Loss: 0.0268 || 10iter: 1.9300 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 350 || Loss: 0.0539 || 10iter: 1.9307 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 360 || Loss: 0.1359 || 10iter: 1.9319 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 370 || Loss: 0.0523 || 10iter: 1.9299 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 380 || Loss: 0.0479 || 10iter: 1.9331 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 390 || Loss: 0.1427 || 10iter: 1.9283 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 400 || Loss: 0.2134 || 10iter: 1.9290 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 410 || Loss: 0.1637 || 10iter: 1.9325 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 420 || Loss: 0.0301 || 10iter: 1.9289 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 430 || Loss: 0.2425 || 10iter: 1.9321 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 440 || Loss: 0.0586 || 10iter: 1.9337 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 450 || Loss: 0.0955 || 10iter: 1.9313 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 460 || Loss: 0.0157 || 10iter: 1.9344 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 470 || Loss: 0.0582 || 10iter: 1.9365 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 480 || Loss: 0.0834 || 10iter: 1.9309 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 490 || Loss: 0.1036 || 10iter: 1.9298 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 500 || Loss: 0.1717 || 10iter: 1.9297 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 510 || Loss: 0.0582 || 10iter: 1.9312 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 520 || Loss: 0.2313 || 10iter: 1.9305 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 530 || Loss: 0.0519 || 10iter: 1.9310 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 540 || Loss: 0.2850 || 10iter: 1.9302 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 550 || Loss: 0.0938 || 10iter: 1.9295 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 560 || Loss: 0.1357 || 10iter: 1.9310 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 570 || Loss: 0.2644 || 10iter: 1.9294 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 580 || Loss: 0.0123 || 10iter: 1.9302 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 590 || Loss: 0.3943 || 10iter: 1.9293 sec. || 本イテレーションの正解率：0.84375\n",
            "イテレーション 600 || Loss: 0.0871 || 10iter: 1.9299 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 610 || Loss: 0.1112 || 10iter: 1.9299 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 620 || Loss: 0.0259 || 10iter: 1.9306 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 630 || Loss: 0.3258 || 10iter: 1.9300 sec. || 本イテレーションの正解率：0.875\n",
            "イテレーション 640 || Loss: 0.1634 || 10iter: 1.9339 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 650 || Loss: 0.2348 || 10iter: 1.9294 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 660 || Loss: 0.0450 || 10iter: 1.9303 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 670 || Loss: 0.0094 || 10iter: 1.9308 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 680 || Loss: 0.0915 || 10iter: 1.9293 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 690 || Loss: 0.3240 || 10iter: 1.9299 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 700 || Loss: 0.2343 || 10iter: 1.9311 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 710 || Loss: 0.0783 || 10iter: 1.9328 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 720 || Loss: 0.1610 || 10iter: 1.9317 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 730 || Loss: 0.1823 || 10iter: 1.9321 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 740 || Loss: 0.2131 || 10iter: 1.9323 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 750 || Loss: 0.0486 || 10iter: 1.9367 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 760 || Loss: 0.0127 || 10iter: 1.9310 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 770 || Loss: 0.2309 || 10iter: 1.9299 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 780 || Loss: 0.2349 || 10iter: 1.9314 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 790 || Loss: 0.0532 || 10iter: 1.9291 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 800 || Loss: 0.3502 || 10iter: 1.9338 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 810 || Loss: 0.0741 || 10iter: 1.9339 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 820 || Loss: 0.0238 || 10iter: 1.9317 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 830 || Loss: 0.0247 || 10iter: 1.9365 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 840 || Loss: 0.3192 || 10iter: 1.9302 sec. || 本イテレーションの正解率：0.84375\n",
            "イテレーション 850 || Loss: 0.2154 || 10iter: 1.9317 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 860 || Loss: 0.2401 || 10iter: 1.9311 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 870 || Loss: 0.0859 || 10iter: 1.9304 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 880 || Loss: 0.1258 || 10iter: 1.9313 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 890 || Loss: 0.0150 || 10iter: 1.9303 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 900 || Loss: 0.2940 || 10iter: 1.9317 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 910 || Loss: 0.1712 || 10iter: 1.9300 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 920 || Loss: 0.1133 || 10iter: 1.9300 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 930 || Loss: 0.1086 || 10iter: 1.9324 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 940 || Loss: 0.1352 || 10iter: 1.9352 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 950 || Loss: 0.1683 || 10iter: 1.9315 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 960 || Loss: 0.1139 || 10iter: 1.9289 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 970 || Loss: 0.0218 || 10iter: 1.9307 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 980 || Loss: 0.0227 || 10iter: 1.9300 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 990 || Loss: 0.0454 || 10iter: 1.9326 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1000 || Loss: 0.1063 || 10iter: 1.9293 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1010 || Loss: 0.1340 || 10iter: 1.9298 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 1020 || Loss: 0.0505 || 10iter: 1.9298 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1030 || Loss: 0.0309 || 10iter: 1.9307 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1040 || Loss: 0.0290 || 10iter: 1.9292 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1050 || Loss: 0.1127 || 10iter: 1.9295 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 1060 || Loss: 0.0376 || 10iter: 1.9316 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1070 || Loss: 0.0382 || 10iter: 1.9299 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1080 || Loss: 0.0488 || 10iter: 1.9317 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1090 || Loss: 0.0577 || 10iter: 1.9306 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1100 || Loss: 0.0708 || 10iter: 1.9303 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1110 || Loss: 0.2663 || 10iter: 1.9312 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 1120 || Loss: 0.2089 || 10iter: 1.9292 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 1130 || Loss: 0.0446 || 10iter: 1.9310 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1140 || Loss: 0.0225 || 10iter: 1.9316 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1150 || Loss: 0.0223 || 10iter: 1.9307 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1160 || Loss: 0.0357 || 10iter: 1.9290 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1170 || Loss: 0.0317 || 10iter: 1.9299 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1180 || Loss: 0.0464 || 10iter: 1.9298 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1190 || Loss: 0.3825 || 10iter: 1.9292 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 1200 || Loss: 0.0465 || 10iter: 1.9297 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1210 || Loss: 0.2573 || 10iter: 1.9299 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 1220 || Loss: 0.1007 || 10iter: 1.9294 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 1230 || Loss: 0.0971 || 10iter: 1.9367 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 1240 || Loss: 0.2151 || 10iter: 1.9330 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1250 || Loss: 0.0097 || 10iter: 1.9298 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1260 || Loss: 0.0093 || 10iter: 1.9307 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1270 || Loss: 0.0328 || 10iter: 1.9305 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1280 || Loss: 0.1819 || 10iter: 1.9308 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1290 || Loss: 0.0122 || 10iter: 1.9294 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1300 || Loss: 0.0717 || 10iter: 1.9294 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1310 || Loss: 0.1230 || 10iter: 1.9302 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1320 || Loss: 0.1034 || 10iter: 1.9333 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 1330 || Loss: 0.1309 || 10iter: 1.9304 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 1340 || Loss: 0.0535 || 10iter: 1.9311 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1350 || Loss: 0.3879 || 10iter: 1.9301 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 1360 || Loss: 0.0686 || 10iter: 1.9303 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1370 || Loss: 0.0556 || 10iter: 1.9302 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1380 || Loss: 0.1922 || 10iter: 1.9308 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1390 || Loss: 0.0222 || 10iter: 1.9314 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1400 || Loss: 0.1099 || 10iter: 1.9306 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1410 || Loss: 0.0445 || 10iter: 1.9318 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1420 || Loss: 0.1179 || 10iter: 1.9322 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 1430 || Loss: 0.0183 || 10iter: 1.9315 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1440 || Loss: 0.0127 || 10iter: 1.9313 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1450 || Loss: 0.1012 || 10iter: 1.9301 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 1460 || Loss: 0.0606 || 10iter: 1.9312 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1470 || Loss: 0.0596 || 10iter: 1.9345 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1480 || Loss: 0.1366 || 10iter: 1.9295 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 1490 || Loss: 0.0212 || 10iter: 1.9348 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1500 || Loss: 0.0708 || 10iter: 1.9316 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1510 || Loss: 0.0820 || 10iter: 1.9312 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 1520 || Loss: 0.0270 || 10iter: 1.9351 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1530 || Loss: 0.2298 || 10iter: 1.9303 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1540 || Loss: 0.0401 || 10iter: 1.9314 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1550 || Loss: 0.0277 || 10iter: 1.9294 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1560 || Loss: 0.0823 || 10iter: 1.9327 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1570 || Loss: 0.0356 || 10iter: 1.9287 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1580 || Loss: 0.0815 || 10iter: 1.9307 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1590 || Loss: 0.1821 || 10iter: 1.9293 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1600 || Loss: 0.0630 || 10iter: 1.9297 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1610 || Loss: 0.0550 || 10iter: 1.9374 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 1620 || Loss: 0.2791 || 10iter: 1.9298 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 1630 || Loss: 0.1370 || 10iter: 1.9318 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 1640 || Loss: 0.2977 || 10iter: 1.9299 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 1650 || Loss: 0.0077 || 10iter: 1.9317 sec. || 本イテレーションの正解率：0.0625\n",
            "Epoch 2/2 | train |  Loss: 0.1183 Acc: 0.9641\n",
            "Epoch 2/2 |  val  |  Loss: 0.1058 Acc: 0.9639\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9ZvsEmzG_Gn"
      },
      "source": [
        ""
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEQFOLAB6jwM"
      },
      "source": [
        "# 学習したネットワークパラメータを保存\n",
        "save_path = './weights/bert_fine_tuning_GAIC_try001_e2_L150.pth'\n",
        "torch.save(net_trained.state_dict(), save_path)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwZII1NIZL9I"
      },
      "source": [
        ""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p09feQVZZP1h"
      },
      "source": [
        "# データの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsNGVYzoJgW2"
      },
      "source": [
        "from utils.bert import get_config, BertModel, set_learned_params\n",
        "# モデル設定のJOSNファイルをオブジェクト変数として読み込み\n",
        "config = get_config(file_path=\"./weights/bert_config.json\")\n",
        "\n",
        "# BERTモデルを作成\n",
        "net_bert = BertModel(config)\n",
        "\n",
        "# BERTモデルに学習済みパラメータセット\n",
        "net_bert = set_learned_params(\n",
        "    net_bert, weights_path=\"'./weights/bert_fine_tuning_GAIC_try001.pth''\")# 学習したパラメータの読み込み\n",
        "\n",
        "\n",
        "#model_path = './weights/bert_fine_tuning_GAIC_try001.pth''\n",
        "netl.load_state_dict(torch.load(model_path))\n",
        "\n",
        "# モデル構築\n",
        "net = BertForGAIC(net_bert)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Evodlc-19Jz"
      },
      "source": [
        "# テストデータの推論"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjZHrofw3Um4"
      },
      "source": [
        "#　テストデータを推論\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "net_trained.eval()   # モデルを検証モードに\n",
        "net_trained.to(device)  # GPUが使えるならGPUへ送る"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXDeRerA3xLq",
        "outputId": "f9576940-dd5e-4e94-da17-6f368f011012"
      },
      "source": [
        "test_ds = data.TabularDataset.splits(\n",
        "    path='./data/', test='GAIC_test.tsv', format='tsv',\n",
        "    fields=[('Text', TEXT)])\n",
        "\n",
        "test_dl = data.Iterator(\n",
        "    test_ds[0], batch_size=batch_size, train=False, sort=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torchtext.legacy.data.dataset.TabularDataset at 0x7fc1f09244d0>"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9QGOkcEN3C3",
        "outputId": "0f805d09-042a-4782-a0d5-6dd04f8c0b40"
      },
      "source": [
        "# テストデータでの正解率を求める\n",
        "Preds = []\n",
        "\n",
        "Test_Loader = tqdm(test_dl)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "net_trained.eval()   # モデルを検証モードに\n",
        "net_trained.to(device)  # GPUが使えるならGPUへ送る\n",
        "\n",
        "for test in Test_Loader:  # testデータのDataLoader\n",
        "    # batchはTextとLableの辞書オブジェクト\n",
        "    # GPUが使えるならGPUにデータを送る\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    inputs = test.Text[0].to(device)  # 文章\n",
        "\n",
        "    # 順伝搬（forward）計算\n",
        "    with torch.set_grad_enabled(False):\n",
        "\n",
        "        # BertForGAICに入力\n",
        "        outputs = net_trained(inputs, token_type_ids=None, attention_mask=None,\n",
        "                              output_all_encoded_layers=False, attention_show_flg=False)\n",
        "        _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
        "        Preds.extend(list(preds.to('cpu').detach().numpy().copy()))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 889/889 [02:44<00:00,  5.42it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bpsumf2nRiXD"
      },
      "source": [
        "# データのアウトプット\n",
        "\n",
        "df = pd.read_table('data/test.tsv', header=0)\n",
        "df[\"pred\"] = Preds\n",
        "df_out = df[[\"sid\", \"pred\"]]\n",
        "df_out.to_csv(\"submission_001.tsv\", header=False, index=False, sep='\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3SEo037ZHm7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29ACkn_-HLGv"
      },
      "source": [
        "# Attentionの可視化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJoHlI3CHJBh"
      },
      "source": [
        "# batch_sizeを64にしたテストデータでDataLoaderを作成\n",
        "batch_size = 64\n",
        "#test_dl = torchtext.data.Iterator(\n",
        "val_dl = data.Iterator(\n",
        "    val_ds, batch_size=batch_size, train=False, sort=False)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyzJUEFlHUWl"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# BertForGAICで処理\n",
        "\n",
        "# ミニバッチの用意\n",
        "batch = next(iter(val_dl))\n",
        "\n",
        "# GPUが使えるならGPUにデータを送る\n",
        "inputs = batch.Text[0].to(device)  # 文章\n",
        "labels = batch.Label.to(device)  # ラベル\n",
        "\n",
        "outputs, attention_probs = net_trained(inputs, token_type_ids=None, attention_mask=None,\n",
        "                                       output_all_encoded_layers=False, attention_show_flg=True)\n",
        "\n",
        "_, preds = torch.max(outputs, 1)  # ラベルを予測\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHiWZ1ynOBry"
      },
      "source": [
        "# HTMLを作成する関数を実装\n",
        "\n",
        "Label_str = {0: \"Other\", 1: \"Green\", 2: \"Environmental\", 3: \"Social\"}\n",
        "\n",
        "def highlight(word, attn):\n",
        "    \"Attentionの値が大きいと文字の背景が濃い赤になるhtmlを出力させる関数\"\n",
        "\n",
        "    html_color = '#%02X%02X%02X' % (\n",
        "        255, int(255*(1 - attn)), int(255*(1 - attn)))\n",
        "    return '<span style=\"background-color: {}\"> {}</span>'.format(html_color, word)\n",
        "\n",
        "\n",
        "def mk_html(index, batch, preds, normlized_weights, TEXT):\n",
        "    \"HTMLデータを作成する\"\n",
        "\n",
        "    # indexの結果を抽出\n",
        "    sentence = batch.Text[0][index]  # 文章\n",
        "    #label = batch.Label[index]  # ラベル\n",
        "    label = int(batch.Label[index].to('cpu').detach().numpy().copy())\n",
        "    pred = int(preds[index].to('cpu').detach().numpy().copy())  # 予測\n",
        "\n",
        "    # ラベルと予測結果を文字に置き換え\n",
        "    \"\"\"\n",
        "    if label == 0:\n",
        "        label_str = \"Negative\"\n",
        "    else:\n",
        "        label_str = \"Positive\"\n",
        "\n",
        "    if pred == 0:\n",
        "        pred_str = \"Negative\"\n",
        "    else:\n",
        "        pred_str = \"Positive\"\n",
        "    \"\"\"\n",
        "    label_str = Label_str[label]\n",
        "    pred_str = Label_str[pred]\n",
        "    \n",
        "    # 表示用のHTMLを作成する\n",
        "    html = '正解ラベル：{}<br>推論ラベル：{}<br><br>'.format(label_str, pred_str)\n",
        "\n",
        "    # Self-Attentionの重みを可視化。Multi-Headが12個なので、12種類のアテンションが存在\n",
        "    for i in range(12):\n",
        "\n",
        "        # indexのAttentionを抽出と規格化\n",
        "        # 0単語目[CLS]の、i番目のMulti-Head Attentionを取り出す\n",
        "        # indexはミニバッチの何個目のデータかをしめす\n",
        "        attens = normlized_weights[index, i, 0, :]\n",
        "        attens /= attens.max()\n",
        "\n",
        "        html += '[BERTのAttentionを可視化_' + str(i+1) + ']<br>'\n",
        "        for word, attn in zip(sentence, attens):\n",
        "\n",
        "            # 単語が[SEP]の場合は文章が終わりなのでbreak\n",
        "            if tokenizer_bert.convert_ids_to_tokens([word.numpy().tolist()])[0] == \"[SEP]\":\n",
        "                break\n",
        "\n",
        "            # 関数highlightで色をつける、関数tokenizer_bert.convert_ids_to_tokensでIDを単語に戻す\n",
        "            html += highlight(tokenizer_bert.convert_ids_to_tokens(\n",
        "                [word.numpy().tolist()])[0], attn)\n",
        "        html += \"<br><br>\"\n",
        "\n",
        "    # 12種類のAttentionの平均を求める。最大値で規格化\n",
        "    all_attens = attens*0  # all_attensという変数を作成する\n",
        "    for i in range(12):\n",
        "        attens += normlized_weights[index, i, 0, :]\n",
        "    attens /= attens.max()\n",
        "\n",
        "    html += '[BERTのAttentionを可視化_ALL]<br>'\n",
        "    for word, attn in zip(sentence, attens):\n",
        "\n",
        "        # 単語が[SEP]の場合は文章が終わりなのでbreak\n",
        "        if tokenizer_bert.convert_ids_to_tokens([word.numpy().tolist()])[0] == \"[SEP]\":\n",
        "            break\n",
        "\n",
        "        # 関数highlightで色をつける、関数tokenizer_bert.convert_ids_to_tokensでIDを単語に戻す\n",
        "        html += highlight(tokenizer_bert.convert_ids_to_tokens(\n",
        "            [word.numpy().tolist()])[0], attn)\n",
        "    html += \"<br><br>\"\n",
        "\n",
        "    return html\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYLgWQsZes6u",
        "outputId": "2d4648cf-d2e4-48b7-e45b-d1e44b8fce68"
      },
      "source": [
        "preds"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        },
        "id": "I84-rGkcOWOS",
        "outputId": "5c340eb3-6747-402e-f895-aefd570e50f9"
      },
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "index = 24  # 出力させたいデータ\n",
        "html_output = mk_html(index, batch, preds, attention_probs, TEXT)  # HTML作成\n",
        "HTML(html_output)  # HTML形式で出力\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "正解ラベル：Social<br>推論ラベル：Other<br><br>[BERTのAttentionを可視化_1]<br><span style=\"background-color: #FFFDFD\"> [CLS]</span><span style=\"background-color: #FFFEFE\"> plaintiffs</span><span style=\"background-color: #FFFEFE\"> all</span><span style=\"background-color: #FFFEFE\"> ##ege</span><span style=\"background-color: #FFFEFE\"> that</span><span style=\"background-color: #FF7A7A\"> l</span><span style=\"background-color: #FF9E9E\"> ##nl</span><span style=\"background-color: #FFE7E7\"> breached</span><span style=\"background-color: #FFF9F9\"> the</span><span style=\"background-color: #FFF9F9\"> terms</span><span style=\"background-color: #FFEEEE\"> of</span><span style=\"background-color: #FFDEDE\"> policy</span><span style=\"background-color: #FFF3F3\"> ##holders</span><span style=\"background-color: #FFF8F8\"> ’</span><span style=\"background-color: #FFF2F2\"> contracts</span><span style=\"background-color: #FFFDFD\"> when</span><span style=\"background-color: #FFF3F3\"> it</span><span style=\"background-color: #FFAFAF\"> increased</span><span style=\"background-color: #FFF8F8\"> non</span><span style=\"background-color: #FFFAFA\"> guaranteed</span><span style=\"background-color: #FFDCDC\"> cost</span><span style=\"background-color: #FFF6F6\"> of</span><span style=\"background-color: #FF0000\"> insurance</span><span style=\"background-color: #FF9E9E\"> rates</span><span style=\"background-color: #FFFBFB\"> in</span><span style=\"background-color: #FFF2F2\"> 2016</span><span style=\"background-color: #FFFCFC\"> and</span><span style=\"background-color: #FFF8F8\"> 2017</span><span style=\"background-color: #FFF9F9\"> .</span><br><br>[BERTのAttentionを可視化_2]<br><span style=\"background-color: #FFFEFE\"> [CLS]</span><span style=\"background-color: #FFFEFE\"> plaintiffs</span><span style=\"background-color: #FFFDFD\"> all</span><span style=\"background-color: #FFFEFE\"> ##ege</span><span style=\"background-color: #FFFBFB\"> that</span><span style=\"background-color: #FFFDFD\"> l</span><span style=\"background-color: #FFF6F6\"> ##nl</span><span style=\"background-color: #FFFEFE\"> breached</span><span style=\"background-color: #FFFCFC\"> the</span><span style=\"background-color: #FFFEFE\"> terms</span><span style=\"background-color: #FFFBFB\"> of</span><span style=\"background-color: #FFC7C7\"> policy</span><span style=\"background-color: #FFEDED\"> ##holders</span><span style=\"background-color: #FFFEFE\"> ’</span><span style=\"background-color: #FFFDFD\"> contracts</span><span style=\"background-color: #FFFEFE\"> when</span><span style=\"background-color: #FFFCFC\"> it</span><span style=\"background-color: #FFFEFE\"> increased</span><span style=\"background-color: #FFFDFD\"> non</span><span style=\"background-color: #FFFEFE\"> guaranteed</span><span style=\"background-color: #FFF4F4\"> cost</span><span style=\"background-color: #FFCDCD\"> of</span><span style=\"background-color: #FF0000\"> insurance</span><span style=\"background-color: #FFF9F9\"> rates</span><span style=\"background-color: #FFFEFE\"> in</span><span style=\"background-color: #FFFEFE\"> 2016</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFEFE\"> 2017</span><span style=\"background-color: #FFFCFC\"> .</span><br><br>[BERTのAttentionを可視化_3]<br><span style=\"background-color: #FFFEFE\"> [CLS]</span><span style=\"background-color: #FFF1F1\"> plaintiffs</span><span style=\"background-color: #FFFCFC\"> all</span><span style=\"background-color: #FFFEFE\"> ##ege</span><span style=\"background-color: #FFFDFD\"> that</span><span style=\"background-color: #FFCACA\"> l</span><span style=\"background-color: #FF0000\"> ##nl</span><span style=\"background-color: #FFF9F9\"> breached</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFAFA\"> terms</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFECEC\"> policy</span><span style=\"background-color: #FFE4E4\"> ##holders</span><span style=\"background-color: #FFFAFA\"> ’</span><span style=\"background-color: #FF0A0A\"> contracts</span><span style=\"background-color: #FFFEFE\"> when</span><span style=\"background-color: #FFF7F7\"> it</span><span style=\"background-color: #FFEFEF\"> increased</span><span style=\"background-color: #FFFEFE\"> non</span><span style=\"background-color: #FFFCFC\"> guaranteed</span><span style=\"background-color: #FFB4B4\"> cost</span><span style=\"background-color: #FFE6E6\"> of</span><span style=\"background-color: #FFCFCF\"> insurance</span><span style=\"background-color: #FFA6A6\"> rates</span><span style=\"background-color: #FFFEFE\"> in</span><span style=\"background-color: #FFFAFA\"> 2016</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFE5E5\"> 2017</span><span style=\"background-color: #FFFEFE\"> .</span><br><br>[BERTのAttentionを可視化_4]<br><span style=\"background-color: #FFDEDE\"> [CLS]</span><span style=\"background-color: #FF0000\"> plaintiffs</span><span style=\"background-color: #FFF6F6\"> all</span><span style=\"background-color: #FFB4B4\"> ##ege</span><span style=\"background-color: #FFDBDB\"> that</span><span style=\"background-color: #FFFCFC\"> l</span><span style=\"background-color: #FFFEFE\"> ##nl</span><span style=\"background-color: #FFFDFD\"> breached</span><span style=\"background-color: #FF6868\"> the</span><span style=\"background-color: #FFFEFE\"> terms</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFF7F7\"> policy</span><span style=\"background-color: #FFFBFB\"> ##holders</span><span style=\"background-color: #FFFEFE\"> ’</span><span style=\"background-color: #FFFDFD\"> contracts</span><span style=\"background-color: #FFFDFD\"> when</span><span style=\"background-color: #FFF5F5\"> it</span><span style=\"background-color: #FFFEFE\"> increased</span><span style=\"background-color: #FFFEFE\"> non</span><span style=\"background-color: #FFFEFE\"> guaranteed</span><span style=\"background-color: #FFFEFE\"> cost</span><span style=\"background-color: #FFFDFD\"> of</span><span style=\"background-color: #FFFBFB\"> insurance</span><span style=\"background-color: #FFFEFE\"> rates</span><span style=\"background-color: #FFFCFC\"> in</span><span style=\"background-color: #FFFDFD\"> 2016</span><span style=\"background-color: #FFFDFD\"> and</span><span style=\"background-color: #FFFDFD\"> 2017</span><span style=\"background-color: #FF2B2B\"> .</span><br><br>[BERTのAttentionを可視化_5]<br><span style=\"background-color: #FFFEFE\"> [CLS]</span><span style=\"background-color: #FFFCFC\"> plaintiffs</span><span style=\"background-color: #FFFEFE\"> all</span><span style=\"background-color: #FFFEFE\"> ##ege</span><span style=\"background-color: #FFFEFE\"> that</span><span style=\"background-color: #FFFEFE\"> l</span><span style=\"background-color: #FFFEFE\"> ##nl</span><span style=\"background-color: #FFFCFC\"> breached</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> terms</span><span style=\"background-color: #FFFDFD\"> of</span><span style=\"background-color: #FFF7F7\"> policy</span><span style=\"background-color: #FFF9F9\"> ##holders</span><span style=\"background-color: #FFFBFB\"> ’</span><span style=\"background-color: #FFFEFE\"> contracts</span><span style=\"background-color: #FFFEFE\"> when</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFFEFE\"> increased</span><span style=\"background-color: #FFFEFE\"> non</span><span style=\"background-color: #FFFEFE\"> guaranteed</span><span style=\"background-color: #FFF8F8\"> cost</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FF0000\"> insurance</span><span style=\"background-color: #FFFDFD\"> rates</span><span style=\"background-color: #FFFEFE\"> in</span><span style=\"background-color: #FFFEFE\"> 2016</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFEFE\"> 2017</span><span style=\"background-color: #FFFEFE\"> .</span><br><br>[BERTのAttentionを可視化_6]<br><span style=\"background-color: #FFFEFE\"> [CLS]</span><span style=\"background-color: #FF0000\"> plaintiffs</span><span style=\"background-color: #FFF0F0\"> all</span><span style=\"background-color: #FFF0F0\"> ##ege</span><span style=\"background-color: #FFF5F5\"> that</span><span style=\"background-color: #FFFEFE\"> l</span><span style=\"background-color: #FFF3F3\"> ##nl</span><span style=\"background-color: #FFBCBC\"> breached</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFAAAA\"> terms</span><span style=\"background-color: #FFE9E9\"> of</span><span style=\"background-color: #FFA9A9\"> policy</span><span style=\"background-color: #FFD2D2\"> ##holders</span><span style=\"background-color: #FFFDFD\"> ’</span><span style=\"background-color: #FF1919\"> contracts</span><span style=\"background-color: #FFF9F9\"> when</span><span style=\"background-color: #FF7A7A\"> it</span><span style=\"background-color: #FFFBFB\"> increased</span><span style=\"background-color: #FFFEFE\"> non</span><span style=\"background-color: #FFEBEB\"> guaranteed</span><span style=\"background-color: #FFFBFB\"> cost</span><span style=\"background-color: #FFFBFB\"> of</span><span style=\"background-color: #FFF6F6\"> insurance</span><span style=\"background-color: #FFF8F8\"> rates</span><span style=\"background-color: #FFFEFE\"> in</span><span style=\"background-color: #FFFEFE\"> 2016</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFEFE\"> 2017</span><span style=\"background-color: #FFFEFE\"> .</span><br><br>[BERTのAttentionを可視化_7]<br><span style=\"background-color: #FFFBFB\"> [CLS]</span><span style=\"background-color: #FFF9F9\"> plaintiffs</span><span style=\"background-color: #FFFEFE\"> all</span><span style=\"background-color: #FFF7F7\"> ##ege</span><span style=\"background-color: #FFFDFD\"> that</span><span style=\"background-color: #FFFEFE\"> l</span><span style=\"background-color: #FFFEFE\"> ##nl</span><span style=\"background-color: #FFFEFE\"> breached</span><span style=\"background-color: #FF5D5D\"> the</span><span style=\"background-color: #FFFEFE\"> terms</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFEFE\"> policy</span><span style=\"background-color: #FFFEFE\"> ##holders</span><span style=\"background-color: #FFFEFE\"> ’</span><span style=\"background-color: #FFFEFE\"> contracts</span><span style=\"background-color: #FFFEFE\"> when</span><span style=\"background-color: #FFFCFC\"> it</span><span style=\"background-color: #FFFEFE\"> increased</span><span style=\"background-color: #FFFEFE\"> non</span><span style=\"background-color: #FFFEFE\"> guaranteed</span><span style=\"background-color: #FFFEFE\"> cost</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFEFE\"> insurance</span><span style=\"background-color: #FFFEFE\"> rates</span><span style=\"background-color: #FFFEFE\"> in</span><span style=\"background-color: #FFFEFE\"> 2016</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFEFE\"> 2017</span><span style=\"background-color: #FF0000\"> .</span><br><br>[BERTのAttentionを可視化_8]<br><span style=\"background-color: #FFFEFE\"> [CLS]</span><span style=\"background-color: #FFFDFD\"> plaintiffs</span><span style=\"background-color: #FFFEFE\"> all</span><span style=\"background-color: #FFFEFE\"> ##ege</span><span style=\"background-color: #FFFEFE\"> that</span><span style=\"background-color: #FFFDFD\"> l</span><span style=\"background-color: #FFFEFE\"> ##nl</span><span style=\"background-color: #FFFEFE\"> breached</span><span style=\"background-color: #FF5151\"> the</span><span style=\"background-color: #FFFEFE\"> terms</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFEFE\"> policy</span><span style=\"background-color: #FFFDFD\"> ##holders</span><span style=\"background-color: #FFFEFE\"> ’</span><span style=\"background-color: #FFFEFE\"> contracts</span><span style=\"background-color: #FFFEFE\"> when</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFFEFE\"> increased</span><span style=\"background-color: #FFFEFE\"> non</span><span style=\"background-color: #FFFEFE\"> guaranteed</span><span style=\"background-color: #FFFEFE\"> cost</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFEFE\"> insurance</span><span style=\"background-color: #FFFEFE\"> rates</span><span style=\"background-color: #FFFDFD\"> in</span><span style=\"background-color: #FFFEFE\"> 2016</span><span style=\"background-color: #FFFDFD\"> and</span><span style=\"background-color: #FFFEFE\"> 2017</span><span style=\"background-color: #FF0000\"> .</span><br><br>[BERTのAttentionを可視化_9]<br><span style=\"background-color: #FFFEFE\"> [CLS]</span><span style=\"background-color: #FFFDFD\"> plaintiffs</span><span style=\"background-color: #FFFEFE\"> all</span><span style=\"background-color: #FFFEFE\"> ##ege</span><span style=\"background-color: #FFFEFE\"> that</span><span style=\"background-color: #FFFDFD\"> l</span><span style=\"background-color: #FFB5B5\"> ##nl</span><span style=\"background-color: #FFBEBE\"> breached</span><span style=\"background-color: #FFFDFD\"> the</span><span style=\"background-color: #FFF1F1\"> terms</span><span style=\"background-color: #FFE4E4\"> of</span><span style=\"background-color: #FFF6F6\"> policy</span><span style=\"background-color: #FFAEAE\"> ##holders</span><span style=\"background-color: #FFFCFC\"> ’</span><span style=\"background-color: #FFFCFC\"> contracts</span><span style=\"background-color: #FFFBFB\"> when</span><span style=\"background-color: #FF0000\"> it</span><span style=\"background-color: #FFCECE\"> increased</span><span style=\"background-color: #FFFEFE\"> non</span><span style=\"background-color: #FFFBFB\"> guaranteed</span><span style=\"background-color: #FFE2E2\"> cost</span><span style=\"background-color: #FFCECE\"> of</span><span style=\"background-color: #FFFCFC\"> insurance</span><span style=\"background-color: #FFF9F9\"> rates</span><span style=\"background-color: #FFFDFD\"> in</span><span style=\"background-color: #FFFEFE\"> 2016</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFEFE\"> 2017</span><span style=\"background-color: #FFFDFD\"> .</span><br><br>[BERTのAttentionを可視化_10]<br><span style=\"background-color: #FFD0D0\"> [CLS]</span><span style=\"background-color: #FFFBFB\"> plaintiffs</span><span style=\"background-color: #FFFCFC\"> all</span><span style=\"background-color: #FFF6F6\"> ##ege</span><span style=\"background-color: #FFF7F7\"> that</span><span style=\"background-color: #FFFEFE\"> l</span><span style=\"background-color: #FFFEFE\"> ##nl</span><span style=\"background-color: #FFFEFE\"> breached</span><span style=\"background-color: #FF4C4C\"> the</span><span style=\"background-color: #FFFEFE\"> terms</span><span style=\"background-color: #FFFDFD\"> of</span><span style=\"background-color: #FFFDFD\"> policy</span><span style=\"background-color: #FFFCFC\"> ##holders</span><span style=\"background-color: #FFFEFE\"> ’</span><span style=\"background-color: #FFFEFE\"> contracts</span><span style=\"background-color: #FFFDFD\"> when</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFFEFE\"> increased</span><span style=\"background-color: #FFFEFE\"> non</span><span style=\"background-color: #FFFEFE\"> guaranteed</span><span style=\"background-color: #FFFEFE\"> cost</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFBFB\"> insurance</span><span style=\"background-color: #FFFEFE\"> rates</span><span style=\"background-color: #FFFDFD\"> in</span><span style=\"background-color: #FFFDFD\"> 2016</span><span style=\"background-color: #FFFDFD\"> and</span><span style=\"background-color: #FFFDFD\"> 2017</span><span style=\"background-color: #FF0404\"> .</span><br><br>[BERTのAttentionを可視化_11]<br><span style=\"background-color: #FFFEFE\"> [CLS]</span><span style=\"background-color: #FFFEFE\"> plaintiffs</span><span style=\"background-color: #FFFEFE\"> all</span><span style=\"background-color: #FFFEFE\"> ##ege</span><span style=\"background-color: #FFFEFE\"> that</span><span style=\"background-color: #FFFEFE\"> l</span><span style=\"background-color: #FFFEFE\"> ##nl</span><span style=\"background-color: #FFFEFE\"> breached</span><span style=\"background-color: #FF5151\"> the</span><span style=\"background-color: #FFFEFE\"> terms</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFEFE\"> policy</span><span style=\"background-color: #FFFEFE\"> ##holders</span><span style=\"background-color: #FFFEFE\"> ’</span><span style=\"background-color: #FFFEFE\"> contracts</span><span style=\"background-color: #FFFEFE\"> when</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFFEFE\"> increased</span><span style=\"background-color: #FFFEFE\"> non</span><span style=\"background-color: #FFFEFE\"> guaranteed</span><span style=\"background-color: #FFFEFE\"> cost</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFDFD\"> insurance</span><span style=\"background-color: #FFFEFE\"> rates</span><span style=\"background-color: #FFFCFC\"> in</span><span style=\"background-color: #FFFEFE\"> 2016</span><span style=\"background-color: #FFF9F9\"> and</span><span style=\"background-color: #FFFEFE\"> 2017</span><span style=\"background-color: #FF0000\"> .</span><br><br>[BERTのAttentionを可視化_12]<br><span style=\"background-color: #FFFEFE\"> [CLS]</span><span style=\"background-color: #FFFEFE\"> plaintiffs</span><span style=\"background-color: #FFFEFE\"> all</span><span style=\"background-color: #FFFEFE\"> ##ege</span><span style=\"background-color: #FFFEFE\"> that</span><span style=\"background-color: #FFFAFA\"> l</span><span style=\"background-color: #FFFCFC\"> ##nl</span><span style=\"background-color: #FFECEC\"> breached</span><span style=\"background-color: #FFFDFD\"> the</span><span style=\"background-color: #FFFDFD\"> terms</span><span style=\"background-color: #FFFBFB\"> of</span><span style=\"background-color: #FFFBFB\"> policy</span><span style=\"background-color: #FFFEFE\"> ##holders</span><span style=\"background-color: #FFFEFE\"> ’</span><span style=\"background-color: #FFFEFE\"> contracts</span><span style=\"background-color: #FFFDFD\"> when</span><span style=\"background-color: #FFFDFD\"> it</span><span style=\"background-color: #FFF9F9\"> increased</span><span style=\"background-color: #FFF6F6\"> non</span><span style=\"background-color: #FFFDFD\"> guaranteed</span><span style=\"background-color: #FFD2D2\"> cost</span><span style=\"background-color: #FFF0F0\"> of</span><span style=\"background-color: #FF0000\"> insurance</span><span style=\"background-color: #FFD1D1\"> rates</span><span style=\"background-color: #FFFBFB\"> in</span><span style=\"background-color: #FFFEFE\"> 2016</span><span style=\"background-color: #FFF6F6\"> and</span><span style=\"background-color: #FFFDFD\"> 2017</span><span style=\"background-color: #FFFDFD\"> .</span><br><br>[BERTのAttentionを可視化_ALL]<br><span style=\"background-color: #FFECEC\"> [CLS]</span><span style=\"background-color: #FF8F8F\"> plaintiffs</span><span style=\"background-color: #FFF8F8\"> all</span><span style=\"background-color: #FFE8E8\"> ##ege</span><span style=\"background-color: #FFF2F2\"> that</span><span style=\"background-color: #FFD6D6\"> l</span><span style=\"background-color: #FFA2A2\"> ##nl</span><span style=\"background-color: #FFD8D8\"> breached</span><span style=\"background-color: #FF5050\"> the</span><span style=\"background-color: #FFE7E7\"> terms</span><span style=\"background-color: #FFEFEF\"> of</span><span style=\"background-color: #FFD1D1\"> policy</span><span style=\"background-color: #FFD6D6\"> ##holders</span><span style=\"background-color: #FFFAFA\"> ’</span><span style=\"background-color: #FF9898\"> contracts</span><span style=\"background-color: #FFFBFB\"> when</span><span style=\"background-color: #FFA7A7\"> it</span><span style=\"background-color: #FFDFDF\"> increased</span><span style=\"background-color: #FFFBFB\"> non</span><span style=\"background-color: #FFF8F8\"> guaranteed</span><span style=\"background-color: #FFD4D4\"> cost</span><span style=\"background-color: #FFDFDF\"> of</span><span style=\"background-color: #FF1F1F\"> insurance</span><span style=\"background-color: #FFCBCB\"> rates</span><span style=\"background-color: #FFFBFB\"> in</span><span style=\"background-color: #FFFAFA\"> 2016</span><span style=\"background-color: #FFFAFA\"> and</span><span style=\"background-color: #FFF7F7\"> 2017</span><span style=\"background-color: #FF0000\"> .</span><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeTC6kIqRoVx",
        "outputId": "4137f4b0-0540-4bde-8ce0-26bcf404f5af"
      },
      "source": [
        "label = batch.Label.to('cpu').detach().numpy().copy()\n",
        "label"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KXCzaFqfLyQ",
        "outputId": "5226d659-78dc-4892-fac5-7d89531eb322"
      },
      "source": [
        "label[24]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jc58YlMLfbPU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}